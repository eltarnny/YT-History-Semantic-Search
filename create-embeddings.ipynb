{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install -U sentence-transformers  \n",
    "! pip install ipywidgets  \n",
    "! pip install trange  \n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  \n",
    "! pip install chromadb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>titleUrl</th>\n",
       "      <th>datetime</th>\n",
       "      <th>transcript</th>\n",
       "      <th>video_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>paragraph_number</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to download your Youtube watch history</td>\n",
       "      <td>https://www.youtube.com/watch?v=dto8jGMxHxY</td>\n",
       "      <td>2024-06-03 08:23:47.724</td>\n",
       "      <td></td>\n",
       "      <td>dto8jGMxHxY</td>\n",
       "      <td>How to download your Youtube watch history</td>\n",
       "      <td>000</td>\n",
       "      <td>dto8jGMxHxY_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build Data Pipelines for ML Projects (w...</td>\n",
       "      <td>https://www.youtube.com/watch?v=OnIQrDiTtRM</td>\n",
       "      <td>2024-06-03 07:44:20.899</td>\n",
       "      <td>when you think of machine learning fancy algor...</td>\n",
       "      <td>OnIQrDiTtRM</td>\n",
       "      <td>How to Build Data Pipelines for ML Projects (w...</td>\n",
       "      <td>000</td>\n",
       "      <td>OnIQrDiTtRM_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build Data Pipelines for ML Projects (w...</td>\n",
       "      <td>https://www.youtube.com/watch?v=OnIQrDiTtRM</td>\n",
       "      <td>2024-06-03 07:44:20.899</td>\n",
       "      <td>when you think of machine learning fancy algor...</td>\n",
       "      <td>OnIQrDiTtRM</td>\n",
       "      <td>is what connects these two things together NE ...</td>\n",
       "      <td>001</td>\n",
       "      <td>OnIQrDiTtRM_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Build Data Pipelines for ML Projects (w...</td>\n",
       "      <td>https://www.youtube.com/watch?v=OnIQrDiTtRM</td>\n",
       "      <td>2024-06-03 07:44:20.899</td>\n",
       "      <td>when you think of machine learning fancy algor...</td>\n",
       "      <td>OnIQrDiTtRM</td>\n",
       "      <td>and columns for example if you're working with...</td>\n",
       "      <td>002</td>\n",
       "      <td>OnIQrDiTtRM_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Build Data Pipelines for ML Projects (w...</td>\n",
       "      <td>https://www.youtube.com/watch?v=OnIQrDiTtRM</td>\n",
       "      <td>2024-06-03 07:44:20.899</td>\n",
       "      <td>when you think of machine learning fancy algor...</td>\n",
       "      <td>OnIQrDiTtRM</td>\n",
       "      <td>the extract process which is acquiring data fr...</td>\n",
       "      <td>003</td>\n",
       "      <td>OnIQrDiTtRM_003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         How to download your Youtube watch history   \n",
       "1  How to Build Data Pipelines for ML Projects (w...   \n",
       "2  How to Build Data Pipelines for ML Projects (w...   \n",
       "3  How to Build Data Pipelines for ML Projects (w...   \n",
       "4  How to Build Data Pipelines for ML Projects (w...   \n",
       "\n",
       "                                      titleUrl                datetime  \\\n",
       "0  https://www.youtube.com/watch?v=dto8jGMxHxY 2024-06-03 08:23:47.724   \n",
       "1  https://www.youtube.com/watch?v=OnIQrDiTtRM 2024-06-03 07:44:20.899   \n",
       "2  https://www.youtube.com/watch?v=OnIQrDiTtRM 2024-06-03 07:44:20.899   \n",
       "3  https://www.youtube.com/watch?v=OnIQrDiTtRM 2024-06-03 07:44:20.899   \n",
       "4  https://www.youtube.com/watch?v=OnIQrDiTtRM 2024-06-03 07:44:20.899   \n",
       "\n",
       "                                          transcript     video_id  \\\n",
       "0                                                     dto8jGMxHxY   \n",
       "1  when you think of machine learning fancy algor...  OnIQrDiTtRM   \n",
       "2  when you think of machine learning fancy algor...  OnIQrDiTtRM   \n",
       "3  when you think of machine learning fancy algor...  OnIQrDiTtRM   \n",
       "4  when you think of machine learning fancy algor...  OnIQrDiTtRM   \n",
       "\n",
       "                                              corpus paragraph_number  \\\n",
       "0         How to download your Youtube watch history              000   \n",
       "1  How to Build Data Pipelines for ML Projects (w...              000   \n",
       "2  is what connects these two things together NE ...              001   \n",
       "3  and columns for example if you're working with...              002   \n",
       "4  the extract process which is acquiring data fr...              003   \n",
       "\n",
       "                id  \n",
       "0  dto8jGMxHxY_000  \n",
       "1  OnIQrDiTtRM_000  \n",
       "2  OnIQrDiTtRM_001  \n",
       "3  OnIQrDiTtRM_002  \n",
       "4  OnIQrDiTtRM_003  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the parquet file of the YouTube History into a pandas dataframe\n",
    "df = pd.read_parquet('output_with_transcripts.parquet')\n",
    "\n",
    "# Function to split text into chunks of max 256 words (recommended length for all-MiniLM-L6-v2)\n",
    "def split_text(text, max_words=256):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "df = df.fillna('')\n",
    "\n",
    "# Create a new column 'video_id' by splitting 'titleURL' after '='\n",
    "df['video_id'] = df['titleUrl'].apply(lambda x: x.split('=')[-1])\n",
    "\n",
    "# Merge 'title' and 'transcript' into a new column 'corpus'\n",
    "df['corpus'] = df['title'] + ' ' + df['transcript']\n",
    "\n",
    "# Split 'corpus' into paragraphs no longer than 256 words\n",
    "df['corpus'] = df['corpus'].apply(split_text)\n",
    "\n",
    "# Explode the dataframe on 'corpus' to get each paragraph in a separate row\n",
    "df = df.explode('corpus').reset_index(drop=True)\n",
    "\n",
    "# Concatenate 'id' with the number of the split paragraph\n",
    "df['paragraph_number'] = df.groupby('video_id').cumcount().astype(str)\n",
    "\n",
    "# Find the maximum number of digits in 'paragraph_number'\n",
    "max_digits = df['paragraph_number'].apply(len).max()\n",
    "\n",
    "# Add zero padding to 'paragraph_number'\n",
    "df['paragraph_number'] = df['paragraph_number'].apply(lambda x: x.zfill(max_digits))\n",
    "\n",
    "# Concatenate 'id' with '_' and the zero padded 'paragraph_number'\n",
    "df['id'] = df['video_id'] + '_' + df['paragraph_number']\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose to use the SentenceTransformer library and not the ChromDB embeddings in case we need more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of embeddings from the corpus\n",
    "corpus = df['corpus'].to_list()\n",
    "embeddings = model.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8252, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing in a vector DB (ChromaDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.trychroma.com/guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for adding to ChromaDB\n",
    "\n",
    "# Create a list of ids\n",
    "ids = df['id'].to_list()\n",
    "# Create a list of dictionaries from the dataframe for the metadata\n",
    "df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "metadata = df[['video_id', 'paragraph_number', 'title', 'titleUrl', 'datetime']].to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"chroma\")\n",
    "collection = chroma_client.get_or_create_collection(name='yt-history')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use upsert instead of add, so the code works for future updates without adding the same data multiple times\n",
    "collection.upsert(\n",
    "    documents=corpus,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadata,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(query_texts=[\"This is a query document\"], n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-YT-History",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
